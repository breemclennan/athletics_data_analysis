---
title: "Athletics Interclub Results Data Analysis"
author: Bree McLennan
date: 01 February 2018
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: cerulean
    highlight: haddock
    df_print: paged
    self_contained: yes
    #fig_width: 7
    #fig_height: 8
    fig_caption: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
options(knitr.table.format = "html") 
options(scipen = 10000) #prevent y axis from scaling
library(dplyr)
library(purrr)
library(data.table)
library(feather)
library(DescTools)
library(RDCOMClient)
library(glue)
library(rprojroot)
library(leaflet)
library(tidyr)
library(knitr)    # For knitting document and include_graphics function
library(ggplot2)  # For plotting
library(png)      # For grabbing the dimensions of png files
library(jpeg)
library(DT)       # For rendering tables
library(knitr)
library(kableExtra)
library(formattable)
library(gridExtra)
`%ni%` <- Negate(`%in%`)
# Define a function that computes file paths relative to where root .git folder is located
F <- is_git_root$make_fix_file() 
# Example usage: F("Data/Raw") , F("Data/Processed")

# Load feather data
wrk.03DataTrans_03 <- setDT(read_feather(glue(F("Data/Processed/wrk.03DataTrans_ForAnalysis.feather"))))

image01_path <- F("Docs/DataReport/Hurdles1.jpg")
```

```{r image01, echo=FALSE, out.width = "75%"}
include_graphics(image01_path)
```


## Purpose & objective of this analysis

The purpose of this project is to uncover and document valued actionable insights which are contained within the available source data for the benefit of the target audience.

The target audience includes coaches, personal trainers, athletes, ahletics governing body officials, interested members of the public, sports enthusiasts, sports statisticians and data scientists.

The objective is to explore Victorian interclub track & field athletic competition results data for the complete 2017-18 summer season and identify:

  *	Natural groupings & patterns within the data
  *	Basic descriptive statistics across the entire dataset
    +	How many competitions per athlete
    +	How many events per athlete
    +	Min, max, averages and quartiles for each event
    +	Geography statistics: By whole of Victorian state and by competition zone/region
  *	Further opportunities for athletics data analysis

**Important note:** This analysis is a not-for-profit independent analysis conducted by Bree McLennan, using publically available data from the [Athletics Victoria Website](http://athsvic.org.au/calendar-results/). This analysis does not represent the opinions of Athletics Victoria.

## Key questions from the target audience to guide this analysis

  1. What are the participation rates at interclub competitions?
    + Can we break this down by zones and clubs?
    + What's the distribution of total competitions athletes participate in during the season?
      - How many events per competition do athletes partake in?
    + How many athletes participated in all rounds of competition?
    + How many athletes competed at "away" venues? (ignoring metro zone v zone)
  2. How many opportunities are there for each event type?
    + Can we see stats by event grouping?
    + What's the most poplar event?
  3. How many incomplete events or invalid event attempts occurred?
  4. Is there any pattern to performances as the season progresses?
  5. How many venues are involved throughout the season?
    + What's the "windiest" venue?
  6. Can we see how points are distributed for performances?
    + What other alternatives to point scoring are there?


## Context specific process flow for this analysis

  0. Define the parameters: Purpose, objective, and rough timelines.
  1. Obtain target audience input.
  2. Obtain source data [Athletics Victoria "AV Shield 2017-18"](http://athsvic.org.au/events/competitions/avcompetitions/av-shield/).
  3. Conduct a risk assessment on source data with respect to purpose & objective.
    + Discarding any data which is not relevant to the analysis guiding questions.
  4. Technical setup to commence analysis:
    + [Github repository](https://github.com/breemclennan/athletics_data_analysis)
    + R Project file.
        - Load data >> Prepare data >> Merge reference data >> Transform data >> Analyse data
  5. Explore data & key guiding questions to discover answers.
  6. Peer review & publish analysis and findings.
  7. Obtain audience feedback, review and apply updates where appropriate.
    + Opportunities to subsequent analysis.


## Analysis data considerations

The data for interclub rounds 1 to 12 is contained in individual csv files, by round, for each participating Victorian region.

General description of the source data:
  
  * Round 7 is excluded because it was cancelled due to extreme weather.
  * There are 77 individual csv files for season 2017-18
  * The CSV file contents can be described as: performance results for each athlete by event completed, for a round of competition for a specific region. Season 2017-18.
  * There are 21 variables in the source data, ranging from athlete registration ID, event specification, performance result, age group, club, venue, wind reading and completion status.
  * Dates and times of competitions and events are not included with the source datasets.
  
Technical approach to creating the analysis data:

  * Append all CSVs together to create one source dataset.
  * Re-name and format variables for data type consistency.
  * Binarise variables where appropriate.
  * Create hierarchial groupings for event types, veues, and age groups.
  * Triage missing data (careful application of subject matter expertise).
    + Particularly with AWD classification performance adjustments, venue names, event specifications and event status (DNQ, INV).
  * Merging on reference data by created keys:
    + Club details (shortname, full name, zone).
    + Venue details (geographical location, track type).
    + Performance adjustment (AWD & masters age group athletes).
  * Calculate athlete finishing order per event and point scoring methods.

## Structure of the created analysis dataset
  
  We commenced with 21 variables in the source dataset. After performing some high level checks on the data we disovered opportunities to
  create new variables (features) by applying context/subject matter expertise and joining relevant reference tables to the source data.
  
  All variables have been renamed to use a three-letter acronym prefix to denote the expected general data type values.
  
  * **KEY:** Primary key.
  * **FOR:** Foreign key, where other tables are referenced and to be joined.
  * **NUM:** Numeric values which have a range beyond binary format, may include NA (Missing/Null).
  * **BIN:** Binary values. 1 and 0 only.
  * **CAT:** Categorical value. Structured and consistent groupings
  * **ORD:** Ordinal value, can be numeric or categorical in origin, but ordering of values is significant.
  * **TXT:** Free/unstructured text.
  * **DTM:** Date-time values. Specifically formatted as YYY-MM-DD HH:MM:SS.ss
<br><br>

```{r wrk.03DataTrans_03, echo=TRUE}
# Analysis dataset structure
glimpse(tbl_df(wrk.03DataTrans_03))

# Count of unique registration numbers (Including "0" and invitational IDs) which have participated in season 2017-18
n_distinct(wrk.03DataTrans_03$KEYRegistrationNumber)
```
<br>

  A random sampling of records from the analysis dataset to demonstrate the visual of what we are working with: 
<br><br>
```{r sample, results='asis'}
# Randomly sample 6 rows from the analysis dataset
head(wrk.03DataTrans_03[sample(nrow(wrk.03DataTrans_03))])

```
<br>

## Exploring the key questions

  **1. What are the participation rates at interclub competitions?**
  
  * Can we break this down by zones and clubs?
  * What's the distribution of total competitions athletes participate in during the season?
    + How many events per competition do athletes partake in?
  * How many athletes participated in all rounds of competition?
  * How many athletes competed at "away" venues? (ignoring metro zone v zone)
    
<br><br>
```{r rows.print=12, echo=TRUE, out.height = "85%"}

# Calculate the participation rates for each round
wrk.03DataTrans_Q1A <- wrk.03DataTrans_03 %>%
  filter(KEYRegistrationNumber %ni% c("0")) %>% #remove teams
  group_by(ORDCompetitionRound) %>%
  summarise(NUMAthletesParticipating = n_distinct(KEYRegistrationNumber),
            NUMTotalEventsParticipated = n(),
            NUMEventsPerAthlete = as.numeric(round((NUMTotalEventsParticipated/NUMAthletesParticipating),digits = 1)) )

# Visualise the dataset
ggplot(wrk.03DataTrans_Q1A, aes(x = ORDCompetitionRound, y = NUMAthletesParticipating )) + 
  geom_bar(stat = "identity", fill ='lightblue') +
  geom_text(aes(label = NUMAthletesParticipating), vjust = 1.6, color = "white",
             size = 3.5) +
  labs(title = "Athlete participation by round",
            x = "Number of athletes",
            y = "Competition round") +
  scale_y_continuous(breaks = c(0,250,500,750,1000,1250,1500))


```
<br>

<br><br>
```{r wrk.03DataTrans_Q1A}

wrk.03DataTrans_Q1A <- wrk.03DataTrans_Q1A %>%
  mutate(NUMAthletesParticipating = color_bar("lightblue")(NUMAthletesParticipating)) %>%
    mutate_at(vars(contains('NUMTotalEvents')), function(x){
    cell_spec(x, "html", color = spec_color(x, option = "C", scale_from = c(800,3400)), bold = TRUE,  background_as_tile = TRUE)}) %>%
    mutate_at(vars(contains('NUMEventsPer')), function(x){
    cell_spec(x, "html", color = spec_color(x, option = "C", begin = 0.1, end = 0.6), bold = TRUE)}) %>%
  kable("html", escape = FALSE, align = "l", caption = "Summary table of athlete participation by round" ) %>%
  kableExtra::kable_styling("hover", full_width = FALSE, position = "left")

wrk.03DataTrans_Q1A

```
We can see from this summary table there is a steady volume of athletes participating in round 1,3 and 4, matched with steady volumes in events participated. There is a clear deviation at round 10, with a drop off in athlete volumes.

Curious questions arise, what could be some potential causal factors for this pattern? Could it be time of year, event schedule/program, or something else?

We know that:

* Rounds 1 to 5 are generally early October to mid November, held in mid-late afternoon
* Rounds 6 to 8 are immediately before the end of year holiday season
* Rounds 9 to 12 are generally in January, held as twilight meets

<br> 
Let's now take a look at the distribution of event participation across rounds.
```{r FreqTableCast}
# Distribution of participation across rounds
# Calculate participation by athlete
    FreqTable <-  as.data.table(xtabs(~ KEYRegistrationNumber + ORDCompetitionRound, wrk.03DataTrans_03))
    FreqTableCast <-  dcast.data.table(FreqTable, KEYRegistrationNumber ~ as.numeric(ORDCompetitionRound), value.var = "N") 
    FreqTableCast_1 <- FreqTableCast %>% 
      mutate(NUMTotalEventsPartipated = rowSums(FreqTableCast[, c(2:12)])) %>%
      mutate(NUMTotalRoundsParticipated = apply(FreqTableCast[, c(2:12)], 1, function(a) sum(a > 0)) )


FreqTableCast_2 <- FreqTableCast_1 %>%
  filter(KEYRegistrationNumber %ni% c("0")) #not including teams
```
<br><br> 

```{r FreqDistribution}
# Visualise: Plot the data points
ggplot(FreqTableCast_2, aes(x = NUMTotalRoundsParticipated, y = NUMTotalEventsPartipated)) + 
  geom_point() +
  labs(title = "Cumulative distribution of event participation across rounds of competition",
            x = "Cumulative number of rounds participated",
            y = "Cumulative count of event participation") +
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11), label = c("1", "2", "3","4","5","6","8","9","10","11","12")) +
  scale_y_continuous(breaks = c(0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75)) +
  stat_summary(fun.y = mean, fun.ymin = min, fun.ymax = max, colour = "blue") +
  geom_smooth(aes(colour = "loess"), method = "loess", se = FALSE) 
```
<br> 
This cumulative distribution reveals:

* The average athlete in the population is likely to participate in at least 2 events per round of competition
* The fitted regression line shows a slightly more positive slope change at round 8. 
* Potential emergence of sub groups
  + Athletes who participate in a single event per round (below average): Could these be niche/specialist event athletes?
  + Average population (the red regression line), participating in two events per round.
  + "Decathletes" (the outliers, above average), athletes who seek to have a go at every event on the program, every round.

<br><br> 
```{r CompetingAllRounds}
# Athletes competing in all rounds of competition
wrk.03DataTrans_Q1B <- wrk.03DataTrans_03 %>%
  filter(KEYRegistrationNumber %ni% c("0")) %>% #remove teams
  group_by(KEYRegistrationNumber) %>%
  summarise(NUMAthletesRounds = n_distinct(ORDCompetitionRound)) %>%
  group_by(NUMAthletesRounds) %>%
  summarise(NUMTotalAthletesAllRounds = n())


wrk.03DataTrans_Q1B <- wrk.03DataTrans_Q1B %>%
  mutate(NUMTotalAthletesAllRounds = color_bar("lightblue")(NUMTotalAthletesAllRounds)) %>%
  kable("html", escape = FALSE, align = "l", caption = "Summary of athlete participation by total number of rounds" ) %>%    kableExtra::kable_styling("hover", full_width = FALSE, position = "left") 

wrk.03DataTrans_Q1B

```
This table highlights, out of nearly 3000 athletes who have competed in the summer interclub season, only 72 participated in all available rounds of competition. That is less than 5% of the athlete population.

A large proportion of athletes participated in up to 4 rounds of competition.

Curious question at this point: What would be the "optimum" number of rounds for an athlete to participate in?

<br><br> 
```{r AwayVenues}
# How many athletes competed at away venues?
wrk.03DataTrans_Q1C <- wrk.03DataTrans_03 %>%
  filter(KEYRegistrationNumber %ni% c("0") & BINAthleteCompeteAwayVenue == 1) %>% #remove teams
  group_by(BINAthleteCompeteAwayVenue) %>%
  summarise(NUMAthletesAway = n_distinct(KEYRegistrationNumber))
 

kable(wrk.03DataTrans_Q1C, "html", align = "l", caption = "Summary of athletes who competed in away venues" ) %>%
  kableExtra::kable_styling("hover", full_width = FALSE, position = "left")

```
This table informs us, nearly 80% of the athlete population competed at a venue which was outside their registered club's Victorian district. At such a broad level view, we don't see the breakdown of clubs. Subject matter expertise suggests that the remaining 20% are likely Victorian country region athletes that don't travel to venues outside their district to compete, while the 80% is likely to be metropolitan.

<br><br>  

**2. How many opportunities are there for each event type?**

  + Can we see stats by event grouping?
  + What's the most poplar event?
    
<br>  
```{r participation, rows.print=12, echo=FALSE}
# Participation by event
wrk.03DataTrans_Q2A <- wrk.03DataTrans_03 %>%
  group_by(ORDCompetitionRound, CATEventFullName, CATEventDiscipline) %>%
  summarise(NUMAthletesParticipating = n_distinct(KEYRegistrationNumber),
            NUMTotalEventsParticipated = n()) %>%
  select(ORDCompetitionRound, CATEventFullName, CATEventDiscipline, NUMAthletesParticipating) %>%
  arrange(desc(NUMAthletesParticipating))
```

```{r TableParticipation, rows.print=12, echo=FALSE}
datatable(wrk.03DataTrans_Q2A, class = "cell-border stripe", caption = 'Participation by event type',
          rowname = FALSE, options = list(autoWidth = TRUE, searching = TRUE))    

#setup the dataset
wrk.03DataTrans_Q2B <- wrk.03DataTrans_Q2A %>%
  ungroup() %>%
  group_by(CATEventFullName) %>%
  summarise(NUMTotalParticipation = sum(NUMAthletesParticipating)) %>%
  arrange(desc(NUMTotalParticipation)) %>%
  head(n = 10)
```
<br><br>
This table displays the details of event participation by round. Sorted by the highest number of athletes participating, the track sprint events 100m and 200m come out on top.

Let's now take a look at the most popular events for the whole season.
<br><br>
```{r VisualParticipation, rows.print=12, echo=FALSE}
# Visualise the dataset
ggplot(wrk.03DataTrans_Q2B, aes(x = reorder(CATEventFullName, -NUMTotalParticipation), y = NUMTotalParticipation )) + 
  geom_bar(stat = "identity", fill = 'lightblue') +
  geom_text(aes(label = NUMTotalParticipation), vjust = 1.6, color = "white", size = 3.5) +
  labs(title = "Athlete participation by event & specification: Top 10 events",
            x = "Event specification",
            y = "Total participation across season")

```
<br><br>
This graph shows us quite clearly the sprint, middle distance and horizontal jumps events dominate in participation rates. It's interesting to note:

* The 800m has higher participation than 400m 
* Shot Put doesn't make it into the top 10
* Highly technical events such as hurdles, steeple, walks and pole vault are not in the top 10.
<br><br>


**3. How many incomplete events or invalid event attempts occurred?**

<br><br>  
```{r incomplete, echo=FALSE}
# incomplete events & invalid attempts
  wrk.03DataTrans_Q3A <- wrk.03DataTrans_03 %>%
    filter(BINValidEventAttempt == 0 & CATAthleteEventStatus %ni% c("OK"))  %>%
    group_by(CATEventFullName, CATAthleteEventStatus) %>%
    summarise(NUMEventStatus = n()) %>%
    arrange(desc(NUMEventStatus))
```

```{r TableIncomplete, echo=FALSE}

datatable(wrk.03DataTrans_Q3A, class = "cell-border stripe", caption = 'Events unsuccessfully completed', rowname = FALSE, options = list(autoWidth = TRUE, searching = TRUE)) 

```
<br><br> 
This table gives us a detailed view as to the nature of a event result being incomplete or unsuccessful.
An event status can be:

* DNF - Did not finish
* DQ - Disqualified (IAAF rule breach)
* NT - No throw recorded
* NM - No measurement made
* DNS - Did not start

The events with the highest incompletion rates are 800m, 400m and 200m. Incomletion could be due to injury or fatigue.

Let's visualise this and observe the events with status stacked.
<br><br> 
```{r VisualIncomplete, echo=FALSE}
# Visualise the dataset
wrk.03DataTrans_Q3B <- wrk.03DataTrans_Q3A %>%
  arrange(desc(NUMEventStatus)) %>%
  head(n = 10)

ggplot(wrk.03DataTrans_Q3B, aes(x = reorder(CATEventFullName, -NUMEventStatus), y = NUMEventStatus, fill = CATAthleteEventStatus )) + 
  geom_bar(stat = "identity") +
  labs(title = "Incomplete Events & Unsuccesful Attempts: Top 10",
            x = "Event specification",
            y = "Total status count") +
  scale_fill_brewer(palette = "Paired")

```
<br><br>  
The visual is consistent with the table above, however we can see some groupings emerge in the field events. 

For field events, is it more appropriate to use "DNF" or "NM" to signify the athlete commenced the event but recorded no final result? Is this a data integrity/consistency of entry issue?
<br><br>  

**4. Is there any pattern to performances as the season progresses?**

We can tackle this question by selecting three events, one from each general track & field discipline:

* Run: We'll select 400m sprint. No wind readings are required, its a circular event, good measure of speed endurance.
* Jump: We'll select Long Jump. It made it into the top 10 events for popularity by participation.
* Throw: We'll select Shot Put. Might prove to be a good measure of power & strength.

Let's observe how the performances of these events vary throughout the season.
  
<br><br>  
```{r patterns, echo=FALSE}
# Lets take an event like 400m. Circular event, wind readings not required. Hypothesis: Good measure of speed endurance & fitness
wrk.03DataTrans_Q4A <- wrk.03DataTrans_03 %>%
  filter(CATEventFullName == "400 Run") %>%
  select(ORDCompetitionRound, CATEventFullName, NUMPerformance, CATGender) 

ggplot(wrk.03DataTrans_Q4A, aes(x = ORDCompetitionRound, y = NUMPerformance, fill = CATGender)) +
  geom_boxplot() +
   scale_fill_brewer(palette = "Blues") +
    labs(title = "RUN: 400m performances by round",
            x = "Competition round",
            y = "Performance in seconds") 
     

# Lets look at long jump
wrk.03DataTrans_Q4B <- wrk.03DataTrans_03 %>%
  filter(CATEventDiscipline == "Long Jump") %>%
  select(ORDCompetitionRound, CATEventFullName, CATEventDiscipline, NUMPerformance, CATGender) 

ggplot(wrk.03DataTrans_Q4B, aes(x = ORDCompetitionRound, y = NUMPerformance, fill = CATGender)) +
  geom_boxplot() +
   scale_fill_brewer(palette = "Blues") +
   labs(title = "JUMP: Long Jump performances by round",
            x = "Competition round",
            y = "Performance in metres") 

# Lets look at a power event like shot put
wrk.03DataTrans_Q4B <- wrk.03DataTrans_03 %>%
  filter(CATEventDiscipline == "Shot Put") %>%
  select(ORDCompetitionRound, CATEventFullName, CATEventDiscipline, NUMPerformance, CATGender) 

ggplot(wrk.03DataTrans_Q4B, aes(x = ORDCompetitionRound, y = NUMPerformance, fill = CATGender)) +
  geom_boxplot() +
   scale_fill_brewer(palette = "Blues") +
   labs(title = "THROW: Shot Put performances by round",
            x = "Competition round",
            y = "Performance in metres") 


```
<br><br>  
A performance trend across the season looks to be a little cloudy and weak. However we do notice for both men and women:

* A larger number of outliers in the 400m, with slower times than average
* The outliers in shotput are all above the mean, throwing better than average
* Most of the outliers in Long Jump are below the mean, jumping less than average

<br><br>  
**5. How many venues are involved throughout the season?**

  + What's the "windiest" venue?
  
The interactive geographical plot below illustrates the venues hosting competitions throughout the season, by round.
The Victorian country region venues do not change round to round, and we notice the Melbourne etropolitan venues change each round.
<br><br>  
```{r geography}

# Setup data to create map plot
wrk.03DataTrans_PlotMap <- wrk.03DataTrans_03 %>%
    filter(KEYRegistrationNumber %ni% c("0")) %>% #remove teams
    group_by(ORDCompetitionRound, CATCompetitionVenue, NUMVenueLatitude, NUMVenueLongitude) %>%
    summarise(NUMAthletes_RV = n_distinct(KEYRegistrationNumber),
              NUMEventsParticipated_RV = n(),
              NUMAvgWindReading_RV = round(mean(!is.na(as.numeric(NUMWindReading))), digits = 3)
    )

# Create a map and plot all venues used during the season

  # Seting up summary dataset for geographical plotting:
  wrk.03DataTrans_PlotMap <- wrk.03DataTrans_03 %>%
    filter(KEYRegistrationNumber %ni% c("0")) %>% #remove teams
    group_by(ORDCompetitionRound, CATCompetitionVenue, NUMVenueLatitude, NUMVenueLongitude) %>%
    summarise(NUMAthletes_RV = n_distinct(KEYRegistrationNumber),
              NUMEventsParticipated_RV = n(),
              NUMMaxWindReading_RV = round(max(as.numeric(NUMWindReading), na.rm = TRUE), digit = 3),
              NUMMinWindReading_RV = round(min(as.numeric(NUMWindReading), na.rm = TRUE), digit = 3),
              NUMAvgWindReading_RV = round(mean(!is.na(as.numeric(NUMWindReading))), digits = 3))
  
  ## Refine the dataset
  venues <- wrk.03DataTrans_PlotMap %>%
    dplyr::mutate(round.nbr = cut(as.numeric(ORDCompetitionRound),c(0,1,2,3,4,5,6,7,8,9,10,11),
                                  labels = c('Round 01', 'Round 02', 'Round 03', 'Round 04', 'Round 05',
                                             'Round 06', 'Round 08', 'Round 09', 'Round 10', 'Round 11', 'Round 12')))
  
  # Create groups to plot
  venues.df <- split(venues, venues$round.nbr)
  
  #Define the leaflet object
  l <- leaflet() %>% addTiles()
  
  
  names(venues.df) %>%
    purrr::walk( function(df) {
      l <<- l %>%
        addMarkers(data = venues.df[[df]],
                   lng = ~NUMVenueLongitude, lat = ~NUMVenueLatitude,
                   label = ~as.character(CATCompetitionVenue), 
                   popup = ~as.character(CATCompetitionVenue),
                   group = df,
                   #clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = F),
                   labelOptions = labelOptions(noHide = F,
                                               direction = 'auto'))
    })
  # Create UI control layer for the map plots
  l %>%
    addLayersControl(
      overlayGroups = names(venues.df),
      options = layersControlOptions(collapsed = FALSE)
    )
  
```  
<br><br>  

Let's look at the venues by wind reading. We'll use the max and min functions across wind reading by venue and round, this is because we know that events which require wind readings can run in multiple directions on competition day.

* Negative wind readings are head wind
* Positive wind readings are tail wind
* Positive wind readings above +2.0 M/sec are considered "illegal" when attempting to break records or achieve qualification standards.
* Just because there is a wind reading does not mean it remained at that speed for the entire competition, but it may serve as an interesting indicator when it shows up at a consistent rate.

<br><br>  
```{r windreadings}
# The windiest venue
wrk.03DataTrans_PlotMap <- wrk.03DataTrans_PlotMap %>%
  ungroup() %>%
  select(ORDCompetitionRound, CATCompetitionVenue, NUMMaxWindReading_RV, NUMMinWindReading_RV) %>%
  arrange(desc(NUMMaxWindReading_RV)) 

datatable(wrk.03DataTrans_PlotMap, class = "cell-border stripe", caption = 'Windiest venues',
          rowname = FALSE,options = list(autoWidth = TRUE, searching = TRUE)) 

```
<br><br>  
The table indicates to us Geelong, Bendigo and Werribee have recorded some of the highest wind readings across the state,
significantly above +2.0 m/s. These may be strong winds, and with curiosity, does this impact performances in any significant way?
<br><br> 

**6. Can we see how points are distributed for performances?**

  + What other alternatives to point scoring are there?
  
This might prove to be a hot topic to cover. The method in which points are calculated can be the difference between a team qualifying for shield final or an athlete receiving an award at the end of season.

This section is dedicated to offering independent thought on alternative options to point scoring, while showing the differences to the current state.

TODO-------EXPLAIN THE METHODS OF CALCULATION
    
<br><br>     
```{r points_A}

# Setup calculated fields
wrk.03DataTrans_SUMM01A <- wrk.03DataTrans_03 %>%
  filter(KEYRegistrationNumber %ni% c("0")) %>% #remove teams
  group_by(KEYRegistrationNumber, CATAgeGroup, CATAthleticClubName, CATClubZoneName) %>%
  summarise(NUMTotalPoints11 = sum(NUMEventFinishOrderPoints11, na.rm = TRUE), 
            NUMTotalAVPointsAwarded = sum(NUMPointsAwarded, na.rm = TRUE), 
            NUMTotalRoundPoints11 = sum(NUMRoundEventFinishOrderPoints11, na.rm = TRUE),
            NUMTotalRoundPoints11AWDAdj = sum(NUMRoundEventFinishOrderPoints11AWDAdj, na.rm = TRUE)) %>%
  arrange(desc(NUMTotalPoints11))

  # GRAPH 1:
  wrk.03DataTrans_SUMM01AA <- head(wrk.03DataTrans_SUMM01A, n = 10)
  ggplot(wrk.03DataTrans_SUMM01AA, aes(x = reorder(KEYRegistrationNumber, -NUMTotalPoints11) , y = NUMTotalPoints11 )) +
  geom_text(aes(label = NUMTotalPoints11), vjust = 1.6, color = "white", size = 3.5) +
  geom_bar(stat = "identity", fill = 'lightblue') +
   labs(title = "AV Shield 2017-18: Points awarded [1st=11]",
            x = "Athlete registration ID",
            y = "Total Points Awarded [11]") 
  
    # Horizontal Barplot [Method Decathlon WR, AV]:
    wrk.03DataTrans_SUMM01B <- wrk.03DataTrans_SUMM01A %>%
      arrange(desc(NUMTotalAVPointsAwarded)) %>%
      head(n =10)
   # GRAPH 2 
  ggplot(wrk.03DataTrans_SUMM01B, aes(x = reorder(KEYRegistrationNumber, -NUMTotalAVPointsAwarded), y = NUMTotalAVPointsAwarded)) +
  geom_text(aes(label = NUMTotalAVPointsAwarded), vjust = 1.6, color = "white", size = 3.5) +
  geom_bar(stat = "identity", fill = 'lightblue') +
  labs(title = "AV Shield 2017-18: Points awarded [AV Shield]",
            x = "Athlete registration ID",
            y = "Total Points Awarded [AV Shield]") 
    
    # Horizontal Barplot [Method 1st=11, 2-9=11minus finish order, >10 = 1 point, by Round]:
    wrk.03DataTrans_SUMM01C <- wrk.03DataTrans_SUMM01A %>%
      arrange(desc(NUMTotalRoundPoints11)) %>%
      head(n = 10)
    
    # Graph 3:
      ggplot(wrk.03DataTrans_SUMM01C, aes(x = reorder(KEYRegistrationNumber, -NUMTotalRoundPoints11), y = NUMTotalRoundPoints11)) +
  geom_text(aes(label = NUMTotalRoundPoints11), vjust = 1.6, color = "white", size = 3.5) +
  geom_bar(stat = "identity", fill = 'lightblue') +
  labs(title = "AV Shield 2017-18: Points awarded [1st=11, round]",
            x = "Athlete registration ID",
            y = "Total Points Awarded [11 by round]") 
    

    # Horizontal Barplot [Method: 1st=11, 2-9=11minus finish order, >10 = 1 
    #                     point, with AWD performance Adjust by Round]:
    wrk.03DataTrans_SUMM01D <- wrk.03DataTrans_SUMM01A %>%
    arrange(desc(NUMTotalRoundPoints11AWDAdj)) %>%
    head(n = 10)
    
    #GRAPH 4:
          ggplot(wrk.03DataTrans_SUMM01D, aes(x = reorder(KEYRegistrationNumber, -NUMTotalRoundPoints11AWDAdj), y = NUMTotalRoundPoints11AWDAdj)) +
  geom_text(aes(label = NUMTotalRoundPoints11AWDAdj), vjust = 1.6, color = "white", size = 3.5) +
  geom_bar(stat = "identity", fill = 'lightblue') +
  labs(title = "AV Shield 2017-18: Points awarded [AWD Adjust,1st=11, round]",
            x = "Athlete registration ID",
            y = "Total Points Awarded [AWD Adjust & 11 by round]") 
    
    
```
<br><br>  
These graphs illustrate that by changing the method of points calculation it does have an impact, at the granular individual athlete level. We observe the ordering of the highest point scoring athletes changes with the method used.

Consider this: If the methods impact at the athlete level, what will happen when it rolls up to club and zone?

<br><br> 

## Summary notes & future analyses

A signficant portion of this analysis was spend on data preparation, cleanup and feature engineering. Spending time carefully assessing the source data helps in establishing a solid foundation to conduct an analysis on.

Observations made in data prep:

* No dates are recorded in the source data. Is this worth adding?
* Inconsistent data entry for athletes with disability, flagging their classification
* Inconsistent data entry for flagging events or athletes as invitation


Thank's for reading, and your thoughts, queries and feedback are welcome and appreciated.

Bree

<br><br>  
